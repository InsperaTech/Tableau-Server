import tableauserverclient as TSC
from datetime import datetime, timedelta, timezone

# Tableau Server information
tableau_server = 'https://your-tableau-server'
username = 'your-username'
password = 'your-password'
site = 'your-site'

# Connect to Tableau Server
tableau_auth = TSC.TableauAuth(username, password, site)
server = TSC.Server(tableau_server)

# Set threshold for stale content (in days)
threshold_days = 45
cutoff_date = datetime.now(timezone.utc) - timedelta(days=threshold_days)

# Connect to Tableau Server and get workbook information
with server.auth.sign_in(tableau_auth):
    all_workbooks, pagination_item = server.workbooks.get()

    # Ensure all datetime objects are timezone-aware
    stale_workbooks = [
        workbook for workbook in all_workbooks
        if datetime.strptime(workbook.updated_at, "%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=timezone.utc) < cutoff_date
    ]

# Display stale workbook information
print("Stale Workbooks:")
for workbook in stale_workbooks:
    print(f"Name: {workbook.name}, Last Updated: {workbook.updated_at}")


------------------------------------------------------------------------------------------------

import argparse
import getpass
import psycopg2
from datetime import datetime, timedelta

def connect_to_postgresql(host, port, user, password, database):
    try:
        connection = psycopg2.connect(
            host=host,
            port=port,
            user=user,
            password=password,
            database=database
        )
        return connection
    except Exception as e:
        print(f"Error: Unable to connect to PostgreSQL database - {e}")
        return None

def get_stale_content(connection, days_threshold=30):
    try:
        cursor = connection.cursor()

        # Query for stale content
        query = """
            SELECT projects.name AS project_name, workbooks.name AS workbook_name, workbooks.updated_at
            FROM workbooks
            JOIN projects ON workbooks.project_id = projects.id
            WHERE current_date - workbooks.updated_at::date > %s;
        """

        cursor.execute(query, (days_threshold,))

        stale_content = cursor.fetchall()

        # Print the stale content
        for row in stale_content:
            project_name, workbook_name, updated_at = row
            print(f"Stale Workbook found: {workbook_name} in Project: {project_name}, Last Updated: {updated_at}")

        cursor.close()
    except Exception as e:
        print(f"Error: Unable to retrieve stale content - {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Connect to Tableau PostgreSQL and get the list of stale content')
    parser.add_argument('--host', '-H', required=True, help='PostgreSQL host')
    parser.add_argument('--port', '-P', type=int, required=True, help='PostgreSQL port')
    parser.add_argument('--user', '-u', required=True, help='PostgreSQL username')
    parser.add_argument('--password', '-p', help='PostgreSQL password')
    parser.add_argument('--database', '-d', required=True, help='PostgreSQL database name')
    parser.add_argument('--days-threshold', '-t', type=int, default=30, help='Number of days to consider as stale (default: 30)')

    args = parser.parse_args()

    # Prompt for password if not provided as a command-line argument
    password = args.password or getpass.getpass('Enter PostgreSQL password: ')

    # Connect to PostgreSQL
    connection = connect_to_postgresql(args.host, args.port, args.user, password, args.database)

    if connection:
        # Get stale content
        get_stale_content(connection, args.days_threshold)

        # Close the database connection
        connection.close()
except Exception as e:
        print(f"Error: Unable to retrieve stale content - {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Connect to Tableau PostgreSQL and get the list of stale content')
    parser.add_argument('--host', '-H', required=True, help='PostgreSQL host')
    parser.add_argument('--port', '-P', type=int, required=True, help='PostgreSQL port')
    parser.add_argument('--user', '-u', required=True, help='PostgreSQL username')
    parser.add_argument('--password', '-p', help='PostgreSQL password')
    parser.add_argument('--database', '-d', required=True, help='PostgreSQL database name')
    parser.add_argument('--days-threshold', '-t', type=int, default=30, help='Number of days to consider as stale (default: 30)')

    args = parser.parse_args()

    # Prompt for password if not provided as a command-line argument
    password = args.password or getpass.getpass('Enter PostgreSQL password: ')

    # Connect to PostgreSQL
    connection = connect_to_postgresql(args.host, args.port, args.user, password, args.database)

    if connection:
        # Get stale content
        get_stale_content(connection, args.days_threshold)

        # Close the database connection
        connection.close()
----------------------------------------------------------------------------
#stale content data based on last updated date
SELECT
    dw.id,
    dw.object_name,
    dw.owner_name,
    dw.project_name,
    dw.type,
    dw.site_name,
    u.friendly_name,
    u.email,
    CONCAT('https://tableau.***.net/#/site/', dw.url_namespace, '/', LOWER(dw.type), 's/', (CASE 
        WHEN dw.type = 'Datasource' THEN dw.dc_id
        WHEN dw.type = 'Workbook' THEN dw.id
    END)) AS URL,
    DATE_PART('day', NOW() - MAX(dw.last_view_time)) AS data_diff,
    dw.luid,
    SUM(dw.size) AS size
FROM
    (
        SELECT
            w.id AS Id,
            'Workbook' AS type,
            w.name AS Object_name,
            w.owner_name,
            w.project_name,
            w.updated_at,
            s.name AS site_name,
            s.url_namespace,
            w.size,
            av.last_view_time,
            av.nviews,
            w.owner_id,
            NULL AS DC_ID,
            w.project_id,
            wb.luid
        FROM
            _workbooks w
            INNER JOIN _sites s ON w.site_id = s.id
            INNER JOIN workbooks wb ON w.id = wb.id
            LEFT JOIN (
                SELECT
                    v.workbook_id,
                    MAX(vs.time) AS last_view_time,
                    SUM(vs.Nviews) AS nviews
                FROM
                    views v
                    LEFT JOIN views_stats vs ON v.id = vs.view_id
                GROUP BY
                    v.workbook_id
            ) AS av ON av.workbook_id = w.id

        UNION ALL

        SELECT
            d.id,
            'Datasource' AS type,
            d.name AS Object_name,
            d.owner_name,
            d.project_name,
            d.updated_at,
            s.name AS site_name,
            s.url_namespace,
            d.size,
            st.last_access_time,
            st.nviews,
            d.owner_id,
            dc.id AS DC_ID,
            d.project_id,
            ds.luid
        FROM
            _datasources d
            LEFT JOIN _datasources_stats st ON d.id = st.datasource_id
            LEFT JOIN data_connections dc ON d.id = dc.datasource_id
            INNER JOIN _sites s ON d.site_id = s.id
            INNER JOIN datasources ds ON d.id = ds.id
        GROUP BY
            d.id,
            d.name,
            d.owner_name,
            d.updated_at,
            d.project_name,
            s.name,
            s.url_namespace,
            d.size,
            st.last_access_time,
            st.nviews,
            d.owner_id,
            dc.id,
            d.project_id,
            ds.luid
    ) dw
LEFT JOIN (
    SELECT
        u.id AS user_id,
        su.email,
        su.friendly_name
    FROM
        _users u
        LEFT JOIN _system_users su ON su.id = u.system_user_id
) u ON dw.owner_id = user_id
WHERE
    NOT dw.project_name = '{destination_project}'
GROUP BY
    dw.id,
    dw.owner_name,
    dw.type,
    dw.site_name,
    u.friendly_name,
    u.email,
    dw.object_name,
    dw.dc_id,
    dw.id,
    dw.url_namespace,
    dw.project_name,
    dw.luid
HAVING
    DATE_PART('day', NOW() - MAX(dw.last_view_time)) >= 100
ORDER BY
    data_diff DESC;

